---
title: "STAT 331 A3"
author: "Kiarash Madji"
date: "2023-11-24"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Q3

```{r}
data <- read.csv("homes.csv")
pairs(data)
```
Suspicious linear association between PropTax/Size which we will need to handle.

```{r}
fit_full <- lm(Price~., dat=data)
library(car)
vif(fit_full)
```

Even though the pair plot for size and property tax looked fairly linear, we see that it is not a big deal given the variance inflation factors are super small. Hence, we do not need to take any action against multicollinearity.

```{r}
qqnorm(rstudent(fit_full))
qqline(rstudent(fit_full), col="red", lwd = 2)
```
With this plot, we see that the normality assumption does not hold. the residuals are not normal as expected in a multiple linear regression model. This plot shows that the tails are simply too fat for the studentized residuals to be normal.

```{r}
data_sqrt <- read.csv("homes.csv")
data_sqrt$Price <- sqrt(data_sqrt$Price)
fit_full_sqrt <- lm(Price~., dat=data_sqrt)
```

```{r}
qqnorm(rstudent(fit_full_sqrt))
qqline(rstudent(fit_full_sqrt), col="red", lwd = 2)
```
This definitely sounds better and fewer datapoints diverge from the normality expectation. Therefore, this transformation is helpful in dealing with the earlier issue.

```{r}
library(glmnet)

predictors = model.matrix(fit_full_sqrt)[,-1]
response = data_sqrt$Price

set.seed(123456789)
fit_lasso = glmnet(x=predictors, y=response, family="gaussian", alpha=1,
lambda=cvfit_lasso$lambda.min)
coef(fit_lasso)
```

## Q4

```{r}
data <- read.csv("hospital_dat_raw.csv")
fit_full <- lm(Stay~., dat=data)
summary(fit_full)
```

Explanatory variates ID, Culture, and Xray are not statistically significant at a 0.05\% level.

```{r}
par(mfrow=c(1, 2))
qqnorm(rstudent(fit_full))
qqline(rstudent(fit_full), col="red", lwd = 2)
plot(fit_full$fitted.values, rstudent(fit_full), xlab = "Fitted Values",
ylab = " Residuals")
abline(h = c(0), lty = 2, col = "red")
```

According to the quantile-quantile plot the normality assumption does not hold as the studentized residuals have fat tails. Outliers exist in data as visible in the residual scatterplot. However, the equal variance assumption holds to a reasonable extent.

```{r}
step_back= step(object = fit_full, direction = "backward", test="F")
summary(step_back)
```
```{r}
forward_selection <- function(data, response, criterion = "adjusted R2", current_model = NULL, progress=FALSE) {
  # data: full dataframe
  # response: name of response variable [string]
  # criterion: "adjusted R2", "AIC", or "BIC"
  # The rest are recursion variables - not to be touched on function call
  
  
  # get the names of the predictors
  predictors <- names(data)[!names(data) %in% response]

  init=FALSE
  # if no current model, initialize it to empty
  if (is.null(current_model)) {
    init=TRUE # so that we print criterion for intercept
    current_model <- list(1)
  }
  # initialize the best model to the current model
  best_model <- current_model
  current_fit <- lm(paste(response, paste(current_model, collapse = " + "), sep = " ~ "), data = data)

  # initialize the best criterion value to the current criterion value
  if (criterion == "adjusted R2") {
    best_criterion_value <- summary(current_fit)$adj.r.squared
  } else if (criterion == "AIC") {
    best_criterion_value <- AIC(current_fit)
  } else if (criterion == "BIC") {
    best_criterion_value <- BIC(current_fit)
  } else {
    stop("Invalid criterion")
  }
  
  # print criterion if this is the intercept-only model
  if (init) {
    print("Intercept (1)")
    print(best_criterion_value)
    print("**********************")
  }
  
  # used to choose the best criterion later
  min_pred <- NULL
  min_crit <- best_criterion_value

  # loop through the predictors
  for (predictor in predictors) {
    # if the predictor is already in the current model, skip it
    if (predictor %in% current_model) {
      next
    }

    # fit the model with new predictor
    model <- lm(paste(response, paste(c(current_model, predictor), collapse = " + "), sep = " ~ "), data = data)

    # get the criterion value
    if (criterion == "adjusted R2") {
      criterion_value <- summary(model)$adj.r.squared
    } else if (criterion == "AIC") {
      criterion_value <- AIC(model)
    } else if (criterion == "BIC") {
      criterion_value <- BIC(model)
    }
    
    # print predictor and its criterion
    print(paste(c(current_model, predictor), collapse = " + "))
    print(criterion_value)

    # if the criterion value is better than the best criterion value, update the best model
    if (criterion_value < min_crit) {
      min_crit <- criterion_value
      min_pred <- predictor
      progress=TRUE # a better situation than starting situation has been identified
    }
  }
  
  # move forward if any changes
  if (progress) {
    best_model <- c(current_model, min_pred)
    print(best_model)
    print("**********************")
    return (forward_selection(data, response, criterion, current_model=best_model))
  }
  
  # stop and return if no changes, catches the case that all predictors are included because progress remains FALSE from the predictor loop
  else {
    return (current_fit)
  }
}
```

```{r}
data <- read.csv("crime_A3.csv")
print(forward_selection(data, "CrimeRate", criterion = "AIC"))
```

